
---

**Amazon CloudWatch** is a monitoring and observability service provided by AWS that helps you collect, visualize, and analyze metrics, logs, and events from AWS resources, applications, and on-premises environments. It enables real-time monitoring of resource utilization, application performance, and operational health. CloudWatch automatically collects default metrics from services like EC2, RDS, Lambda, and DynamoDB and allows you to define custom metrics as well.

CloudWatch features include **dashboards** for visualizing metrics, **alarms** to trigger notifications or actions when thresholds are crossed, **logs** for centralized log collection and analysis, and **CloudWatch Events (now called EventBridge)** for event-driven automation. It plays a key role in detecting anomalous behavior, troubleshooting issues, and maintaining system performance and availability in cloud-native architectures.

Metrics refer to time ordered set of data points that are published to CloudWatch.

### **1. Data Sources**

CloudWatch collects data from three main sources:

- **AWS Services**: Metrics are automatically emitted by AWS services like EC2, RDS, Lambda, DynamoDB, S3, etc. For example, EC2 sends CPUUtilization, NetworkIn/Out, and DiskReadOps metrics every minute (or one second for detailed monitoring).
- **Custom Applications**: You can publish custom metrics using the AWS SDK, CLI, or API. For example, a web app can push response times or number of logged-in users.
- **Logs**: Applications or services can send logs to **CloudWatch Logs** using the CloudWatch Agent or through direct API calls. Logs can come from EC2, Lambda, ECS, on-premises servers, etc.

### **2. Metrics Collection and Storage**

CloudWatch stores **metrics as time-series data**, which includes:

- Metric name (e.g., `CPUUtilization`)
- Dimensions (e.g., `InstanceId`)
- Timestamps and values
- Namespace (e.g., `AWS/EC2`, `Custom/AppMetrics`)

You can store data with resolutions of 1-minute (standard) or 1-second (high-resolution metrics). Data retention varies: 15 months by default with different granularities (e.g., 1-minute data for 15 days, 5-minute for 63 days, etc.).

### **3. Log Management**

Logs are ingested and stored in **Log Groups**, each containing **Log Streams** (e.g., logs per EC2 instance or Lambda function). CloudWatch provides:
- **Log Insights**: A query engine to search, filter, and analyze logs.
- **Metric Filters**: You can extract numerical values from logs and turn them into CloudWatch metrics.

Log groups is composed of log streams all share same retention and permission settings.

You can create **dashboards** to visualize metrics and logs using widgets (line graphs, number displays, text, etc.). Dashboards can combine metrics from multiple services across regions for a unified view.


**CloudWatch Alarms** let you monitor metrics and trigger actions:

- Define a **threshold** (e.g., CPU > 80% for 5 minutes).
- Alarm transitions between OK, ALARM, and INSUFFICIENT_DATA states.
- You can send notifications via **SNS**, trigger **Auto Scaling**, or **Lambda functions**.


Formerly known as CloudWatch Events, **Amazon EventBridge** enables **event-driven automation**:

- It captures events from AWS services (e.g., EC2 instance terminated) or custom events.
- You can define **rules** to match events and route them to targets like Lambda, Step Functions, SQS, etc.


- **CloudWatch Agent**: Installed on EC2 or on-prem servers to send system-level metrics and logs (disk usage, memory, app logs).
- **Unified CloudWatch Agent**: Supports both metrics and logs in one agent.
- **Embedded Metric Format (EMF)**: A way to embed structured JSON logs that can be automatically turned into metrics.

#### Custom metrics

**Custom metrics** in Amazon CloudWatch allow you to publish and monitor application-specific data that is not provided by default AWS services. These metrics are useful when you want to track performance indicators, business logic outcomes, or application internals—such as number of active users, job queue size, or transaction latency.

### Cloud watch alarms:

Autmatically initiate actions based on sustained changes to metrics. We must declare which metric alarm will be set up for then define threshold and time period. You will not want to trigger alarm based on small temporary spikes. Actions can be EC2 action, auto scale or notification sent to Notification service.

Availability:

Based on number of nines.

There are two kinds of high available systems:

1. Active passive system - Only one of many instance available at a time. Its good for stateful application(data of client is stored on server). But only vertical scaling is possbile
2. Active active system - All instances can handle query. Stateless and thus horizontal scalable.

#### Load Balancers:

Distrubute the load on multiple set of resources based on certain algorithm. ELB(elastic load balancer) is amazon product for handling laod balancing.

Health checks are done by load balancers to ensure which instances are up and runing. It is responsibility of ELB to determine which instances are not working and use autoscaling.

ELB components:

There are three main types:

- **Application Load Balancer (ALB)** – Best for HTTP/HTTPS and advanced routing.
- **Network Load Balancer (NLB)** – Best for TCP/UDP and high-performance use cases.
- **Gateway Load Balancer (GWLB)** – Used for third-party virtual appliances (firewalls, etc.).

#### Listeners

Listeners are rules that define how the load balancer processes incoming connections. A listener checks for connection requests on a **port** (e.g., port 80 for HTTP) and **protocol** (HTTP, HTTPS, TCP, etc.) and forwards them according to defined **rules**.

#### Target Groups

A target group is a logical grouping of resources (targets) like EC2 instances, ECS containers, or IPs that the load balancer can route traffic to. You define **health checks** for target groups to ensure only healthy targets receive traffic. A load balancer can have multiple target groups, each with its own routing rules.
#### Targets

These are the actual resources that process requests. Targets can be:

- EC2 instances
- ECS tasks
- Lambda functions (only with ALB)
- IP addresses (for on-prem or external resources)

#### Rules (for ALB)

In Application Load Balancers, you can define **routing rules** based on conditions like path (`/api/*`), host (`api.example.com`), or headers. Rules decide which target group the request should be routed to.

#### Security Groups and Subnets

Security groups control access to the ELB, and subnets determine in which Availability Zones the load balancer is active. For internet-facing ELBs, at least one subnet must be public.

## EC2 autoscale:

Amazon EC2 Auto Scaling helps you maintain application availability and scale your EC2 instances automatically according to demand. It ensures that you always have the right number of instances running to handle the load, and can replace unhealthy instances to maintain performance and resilience. The configuration involves several key components that work together to manage scaling efficiently.

Configuring EC2 Auto Scaling starts with defining your desired infrastructure behavior. You begin by creating a launch template or launch configuration that specifies the instance settings, such as the AMI ID, instance type, key pair, security groups, and any user data scripts. Once this is ready, you create an Auto Scaling group that uses these settings to launch and manage instances across specified Availability Zones. The group ensures that your application can handle failure zones and distributes instances evenly across them.

Launch templates are the preferred way to define instance configuration details. They support more features than launch configurations and are reusable across different Auto Scaling groups. A launch template contains parameters like the Amazon Machine Image (AMI), instance type, network interfaces, security groups, and block device mappings. You can create multiple versions of a launch template to manage changes over time without disrupting existing resources. This provides flexibility and control in managing deployments and scaling configurations.

An Auto Scaling group (ASG) is the core component that manages a fleet of EC2 instances. It defines the minimum, maximum, and desired number of instances and automatically scales your fleet within these boundaries. The ASG uses health checks to monitor instance health and can replace unhealthy instances automatically. It also supports integrating with Elastic Load Balancers to distribute incoming traffic across the healthy instances within the group. Placement across multiple Availability Zones ensures high availability and fault tolerance.

Scaling policies determine how the Auto Scaling group should respond to changes in demand. You can use dynamic scaling policies that adjust capacity based on metrics like CPU utilization or request count, or you can use predictive scaling, which forecasts future traffic and proactively adjusts capacity. Target tracking scaling is a common policy that adjusts instance count to maintain a specified metric target (e.g., keeping average CPU at 50%). You can also configure scheduled scaling to increase or decrease capacity at specific times, useful for known traffic patterns.

There are mainly three scaling policies:

1. Simple: We use cloudwatch alarm to specify when it will be invoked. And then we can add or remove number of EC2 instances. Once scaling is invoked it enters cooldown period before taking any action.
2. Step: IT responds to additonal alarms even when scaling activity or health check is in progress. 
3. Target: This is used when we want to maintain certain metric for eg CPU utilization to be 70%. 

